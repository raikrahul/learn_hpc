---
layout: default
title: "Lesson 3: Parallel Summation Using OpenMP"
date: 2024-03-06
---

# Lesson 3: Parallel Summation Using OpenMP

## **Introduction**
This lesson covers **parallel summation** using **OpenMP** in C. The program demonstrates:
- **Memory allocation**
- **Random number initialization**
- **Parallel computation using OpenMP**
- **Handling race conditions with critical sections**

It also highlights potential pitfalls like **floating-point errors, memory allocation failures, and load imbalance issues**.

---

## **Code Explanation & Annotations**
Below is the annotated **C code** for parallel summation using OpenMP.

```c
#include <stdio.h>  // stdio.h (1) - Risk: BOF with printf, HPC I/O slow!
                    // L1-API: C std I/O library. printf, fprintf -> BOF risk.
                    // L2-Algo: Formatted I/O is slow for HPC workloads.
                    // L4-Edge: Format string vulnerabilities. Code execution risk.

#include <stdlib.h> // stdlib.h (2) - malloc failure risk, atoi input vulnerability.
                    // L1-API: malloc, atoi, exit. Memory allocation failure possible.
                    // L2-Algo: Always check malloc failure in HPC.
                    // L4-Edge: atoi input validation critical - non-int input crash?

#include <omp.h>    // omp.h (3) - OpenMP support: Race conditions, thread safety issues.
                    // L1-API: OpenMP directives, shared memory model -> Risk of race conditions.
                    // L3-HPC: OpenMP enables shared memory parallelism. Requires proper synchronization.

#include <time.h>   // time.h (4) - Used for RNG seeding. Time resolution concerns.
                    // L1-API: time(), srand(), clock(). 
                    // L2-Algo: RNG seeding with time is okay for simple cases but not HPC RNG.

/// Function to compute local sum within a thread's assigned range
double calculateLocalSum(int start, int end, double* data) {  // Function (5)
    if (start >= end) return 0.0;  // Handle empty section (6)
    double localSum = 0.0;         // Initialize sum (7) - Floating-point precision loss possible.
    for (int i = start; i < end; ++i) {  // Loop through assigned range (8)
        localSum += data[i];  // Accumulate sum (9) - Risk: Floating-point error propagation.
    }
    return localSum;  // Return computed local sum (10)
}

int main(int argc, char* argv[]) {  // Main function (11) - Entry point.
    if (argc < 2) {  // Validate command-line arguments (12)
        fprintf(stderr, "Usage: %s <N>\n", argv[0]);  // Error message (13)
        return 1;  // Exit due to missing input (14)
    }

    int N = atoi(argv[1]);  // Convert CLI arg to integer (15)
    if (N <= 0) {  // Validate input (16)
        fprintf(stderr, "N must be a positive integer.\n");  // Error message (17)
        return 1;  // Exit on invalid input (18)
    }

    // Memory allocation
    double* data = (double*)malloc(N * sizeof(double));  // Allocate memory (20)
    if (!data) {  // Check allocation success (21)
        fprintf(stderr, "Memory allocation failed.\n");  // Error message (22)
        return 1;  // Exit if malloc fails (23)
    }

    // Initialize array with random values
    srand(time(NULL));  // Seed RNG (24) - Time resolution issue?
    for (int i = 0; i < N; ++i) {  // Initialize loop (25)
        data[i] = (double)rand() / RAND_MAX * 100.0;  // Generate values in [0,100] (26)
    }

    double globalSum = 0.0;  // Shared global sum (28) - Potential race condition.

    // OpenMP parallel region
    #pragma omp parallel num_threads(8) shared(data, N, globalSum)
    { 
        int thread_id = omp_get_thread_num();  // Get thread ID (31)
        int total_threads = omp_get_num_threads();  // Get total thread count (32)
        double localSum;  // Private variable for each thread (33)

        // Compute work distribution
        int base_block_size = N / total_threads;  // Base work per thread (34)
        int remainder = N % total_threads;  // Compute remainder (35)
        int block_size = base_block_size + (thread_id < remainder ? 1 : 0);  // Adjust block size (36)
        int start_index = (thread_id < remainder) 
                          ? thread_id * (base_block_size + 1) 
                          : remainder * (base_block_size + 1) + (thread_id - remainder) * base_block_size;  // Start index (38)
        int end_index = start_index + block_size;  // End index (40)

        // Compute local sum
        localSum = calculateLocalSum(start_index, end_index, data);  // Compute sum (41)

        // Critical section to update shared global sum
        #pragma omp critical  // Serial region (42) - Causes performance bottleneck.
        { 
            globalSum += localSum;  // Update global sum (44)
        } 
        printf("Thread %d: Local Sum: %lf (Indices: %d to %d)\n", thread_id, localSum, start_index, end_index - 1);  // Debug output (46)
    }

    printf("Global Sum: %lf\n", globalSum);  // Print final result (48)
    free(data);  // Free allocated memory (49)

    return 0;  // Exit program (50)
}
