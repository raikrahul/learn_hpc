---
layout: default
title: "Lesson 3: Parallel Summation Using OpenMP"
date: 2024-03-06
---

**Lesson 3: Parallel Summation Using OpenMP**

```markdown


# Lesson 3: Parallel Summation Using OpenMP

## Introduction
This lesson covers **parallel summation** using **OpenMP** in C. The program demonstrates:
- **Memory allocation**
- **Random number initialization**
- **Parallel computation using OpenMP**
- **Handling race conditions with critical sections**

---

## Code Explanation & Annotations

```c
#include <stdio.h> // stdio.h (1) - printf = I/O bottleneck HPC! BOF risk.
#include <stdlib.h> // stdlib.h (2) - malloc fail check crucial, atoi vuln.
#include <omp.h> // omp.h (3) - OpenMP: Race Conditions, Thread Safety Alert!
#include <time.h> // time.h (4) - time for srand seed - low res for HPC?

// Function to compute local sum
double calculateLocalSum(int start, int end, double* data) { // localSum (5)
    if (start >= end) return 0.0; //Handle empty section (6) - Edge case check ok.
    double localSum = 0.0; // Local sum init (7) - Float error accumulate?
    for (int i = start; i < end; ++i) { // Local sum loop (8)
        localSum += data[i]; // Accumulate local sum (9) - Float error risk over N.
                             // L4-Edge: Float rounding error if N very large for sum.
                             // AI & ML Bug: Potential AI Model Divergence from round err.
    }
    return localSum; // Return local sum (10)
}

int main(int argc, char* argv[]) { // Main func (11)
    if (argc < 2) { // Arg check (12) - Missing N arg error case.
        fprintf(stderr, "Usage: %s <N>\n", argv[0]); // Usage msg (13) - stderr I/O slow HPC
        return 1; // Exit usage error (14)
    }

    int N = atoi(argv[1]); // N from arg (15) - atoi input validation needed!
    if (N <= 0) { // Validate N>0 (16) - N non-positive input error.
        fprintf(stderr, "N must be a positive integer.\n"); // N err msg (17) - stderr I/O
        return 1; // Exit N error (18)
    }

    double* data = (double*)malloc(N * sizeof(double)); // malloc data (19) - Malloc MUST be checked for fail! Mem leak risk if not handled right!.
    if (!data) { // Malloc fail check (20) - CRITICAL malloc check - prevent crash!
        fprintf(stderr, "Memory allocation failed.\n"); // Malloc err msg (21) - stderr I/O slow
        return 1; // Exit malloc fail (22)
    }

    srand(time(NULL)); // Seed RNG (23) - time(NULL) low res, repeat seeds?
                        // L4-Edge: time(NULL) seed if loops too fast - repeat seeds!
                        //         Not HPC quality RNG. For tests ok, not for real sim.
    for (int i = 0; i < N; ++i) { // Init data loop (24) - O(N) init. Cache issues?
        data[i] = (double)rand() / RAND_MAX * 100.0; // Init with rand (25) - rand() bias? HPC RNG better!
                       // L2-Algo: rand() bias - ok example, HPC needs better RNG.
    }

    double globalSum = 0.0; // Global sum init (26) - Shared, potential race cond.
                            // L3-HPC: Global var 'globalSum' SHARED in parallel region -> Race Cond!

    #pragma omp parallel num_threads(8) shared(data, N, globalSum) // Parallel (27) - Race cond on globalSum? Critical misuse?
    { // OpenMP parallel block (28)
        int thread_id = omp_get_thread_num(); // Thread ID (29) - thread-private ok.
        int total_threads = omp_get_num_threads(); // Total threads (30) - thread-private.
        double localSum; // Local sum var (31) - thread-private ok, no race.

        int base_block_size = N / total_threads; // Base block size (32) - Int div, Load Imbalance?
        int remainder = N % total_threads; // Remainder calc (33) - Load balance uneven N?
        int block_size = base_block_size + (thread_id < remainder ? 1 : 0); // Block size (34) - Load balance, still uneven workload per thread data?
        int start_index = (thread_id < remainder) // Start index (35) - Load balance index calcs - error prone? Off-by-one bugs?
                          ? thread_id * (base_block_size + 1)
                          : remainder * (base_block_size + 1) + (thread_id - remainder) * base_block_size;
        int end_index = start_index + block_size; // End index (36) - Potential off by one here too in index math for load balance block split!

        localSum = calculateLocalSum(start_index, end_index, data); // Local sum call (37) - Private sum calc. No Race Condition HERE, inside local sum function isolated OK.

        #pragma omp critical // Critical section (38) - Serial bottleneck! Perf impact HUGE! Contention.
        { // Critical section start (39) - Serialize globalSum update - BAD perf!
            globalSum += localSum; // Global sum += (40) - Protected but serializes! Perf KILLS.
                                // L2-Algo: Critical section SERIAL - Amdahl's law = perf limit.
                                // L3-HPC: Contention on lock. Thread Starvation. Perf tank.
                                // L4-Edge: Deadlock risk with nested criticals in real code!
                                // CTO Rec: Atomic ops BETTER, reduction PRAGMA BEST!
        } // Critical section end (41) - Serial section ends - perf hit over.

        printf("Thread %d: Local Sum: %lf (Indices: %d to %d)\n", thread_id, localSum, start_index, end_index - 1); // Thread printf (42) - Parallel I/O - serialization. Perf impact!
    } // End parallel (43) - Implicit barrier - Load Imbalance? Starvation?

    printf("Global Sum: %lf\n", globalSum); // Final global sum print (44) - Serial print, ok now.
    free(data); // Free data (45) - Memory MUST be freed - leak if missing!
                // Memory & Cache Issues: Memory leak if free MISSING. Valgrind!

    return 0; // Exit main (46) - Clean exit - no HPC bugs on exit.
}
```

---

## Key Takeaways
- **Memory Allocation Risks:** Always check if `malloc()` fails.
- **Race Condition Prevention:** Protect shared variables using `#pragma omp critical` (or `#pragma omp reduction` for better performance).
- **Floating-Point Precision Issues:** Summing large arrays can introduce rounding errors.
- **Load Balancing Issues:** Ensure all threads get an equal workload.
- **I/O Bottlenecks:** `printf()` inside parallel sections slows execution.

---

## Optimizations for HPC Workloads
- **Use `#pragma omp reduction(+:globalSum)` instead of `#pragma omp critical`**
- **Consider high-precision floating-point techniques to minimize summation errors**
- **Use better random number generators (e.g., MT19937) for scientific computations**

---

## Conclusion
This program demonstrated **parallel summation with OpenMP**, highlighting **race conditions, memory allocation risks, and load balancing issues**. OpenMP allows efficient **multi-core computation**, but **proper synchronization and load balancing** are critical for performance.
```


