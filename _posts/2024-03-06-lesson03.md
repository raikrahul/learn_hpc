---
layout: default
title: "Lesson 3: Parallel Summation Using OpenMP"
date: 2024-03-06
---

# Lesson 3: Parallel Summation Using OpenMP

## Introduction
This lesson covers **parallel summation** using **OpenMP** in C. The program demonstrates:
- **Memory allocation**
- **Random number initialization**
- **Parallel computation using OpenMP**
- **Handling race conditions with critical sections**

---

## Code Explanation & Annotations

{% highlight c %}
#include <stdio.h>
#include <stdlib.h>
#include <omp.h>
#include <time.h>

// Function to compute local sum
double calculateLocalSum(int start, int end, double* data) {
    if (start >= end) return 0.0;
    double localSum = 0.0;
    for (int i = start; i < end; ++i) {
        localSum += data[i]; 
    }
    return localSum;
}

int main(int argc, char* argv[]) {
    if (argc < 2) {
        fprintf(stderr, "Usage: %s <N>\n", argv[0]);
        return 1;
    }

    int N = atoi(argv[1]);
    if (N <= 0) {
        fprintf(stderr, "N must be a positive integer.\n");
        return 1;
    }

    double* data = (double*)malloc(N * sizeof(double));
    if (!data) {
        fprintf(stderr, "Memory allocation failed.\n");
        return 1;
    }

    srand(time(NULL));
    for (int i = 0; i < N; ++i) {
        data[i] = (double)rand() / RAND_MAX * 100.0;
    }

    double globalSum = 0.0;

    #pragma omp parallel num_threads(8) shared(data, N, globalSum)
    {
        int thread_id = omp_get_thread_num();
        int total_threads = omp_get_num_threads();
        double localSum;

        int base_block_size = N / total_threads;
        int remainder = N % total_threads;
        int block_size = base_block_size + (thread_id < remainder ? 1 : 0);
        int start_index = (thread_id < remainder) 
                          ? thread_id * (base_block_size + 1) 
                          : remainder * (base_block_size + 1) + (thread_id - remainder) * base_block_size;
        int end_index = start_index + block_size;

        localSum = calculateLocalSum(start_index, end_index, data);

        #pragma omp critical
        { 
            globalSum += localSum;
        }

        printf("Thread %d: Local Sum: %lf (Indices: %d to %d)\n", thread_id, localSum, start_index, end_index - 1);
    }

    printf("Global Sum: %lf\n", globalSum);
    free(data);

    return 0;
}
{% endhighlight %}

---

## Key Takeaways
- **Memory Allocation Risks:** Always check if `malloc()` fails.
- **Race Condition Prevention:** Protect shared variables using `#pragma omp critical` (or `#pragma omp reduction` for better performance).
- **Floating-Point Precision Issues:** Summing large arrays can introduce rounding errors.
- **Load Balancing Issues:** Ensure all threads get an equal workload.
- **I/O Bottlenecks:** `printf()` inside parallel sections slows execution.

---

## Optimizations for HPC Workloads
- **Use `#pragma omp reduction(+:globalSum)` instead of `#pragma omp critical`**  
- **Consider high-precision floating-point techniques to minimize summation errors**  
- **Use better random number generators (e.g., MT19937) for scientific computations**  

---

## Conclusion
This program demonstrated **parallel summation with OpenMP**, highlighting **race conditions, memory allocation risks, and load balancing issues**. OpenMP allows efficient **multi-core computation**, but **proper synchronization and load balancing** are critical for performance.
