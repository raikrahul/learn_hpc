```markdown
layout: default
title: "Lesson 5: OpenMP Scheduling and Reduction"
date: 2024-03-08
---

## Lesson 5: OpenMP Scheduling and Reduction

### OpenMP Scheduling

Scheduling determines loop iteration distribution among threads, impacting performance.

*   **Static:** Fixed, pre-loop assignment. Low overhead, best for balanced work.

    ```c
    // Static Scheduling
    omp_set_schedule(omp_sched_static, 0);
    #pragma omp parallel for
    for (int i = 0; i < N; i++) {
        result += a[i];
    }
    ```

*   **Dynamic:** Chunk-based assignment as threads free up. Better for uneven work, higher overhead.

    ```c
    // Dynamic Scheduling
    omp_set_schedule(omp_sched_dynamic, chunk_size);
    #pragma omp parallel for
    for (int i = 0; i < N; i++) {
        result += a[i];
    }
    ```

*   **Guided:** Decreasing chunk size dynamic scheduling. Balances overhead and uneven work.

    ```c
    // Guided Scheduling
    omp_set_schedule(omp_sched_guided, chunk_size);
    #pragma omp parallel for
    for (int i = 0; i < N; i++) {
        result += a[i];
    }
    ```

*   **Auto & Runtime:** Compiler/runtime or environment variable controlled scheduling.

**Schedule Choice:** Static for balanced loops, Dynamic/Guided for imbalanced loops.

### OpenMP Reduction Clause

`reduction` ensures correct combination of parallel thread results, preventing data races in operations like sum.

*   **Purpose:** Safe combination of thread-local results into a shared variable.
*   **Mechanism:** Private copies, partial sums, operator-based combination.

**Example (Reduction for Dot Product):**

```c
    // Dot product with reduction
    #pragma omp parallel for reduction(+:result)
    for (int i = 0; i < n; i++) {
      result += a[i] * b[i];
    }
```

**Correctness is Key:**  Always use `reduction` for parallel reductions to avoid data races and ensure accurate results.

**Summary:** Scheduling for performance, Reduction for correctness in parallel loops.
```
